{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOcMpWqz5wb8VjgankfXjFR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2GHTIZ9Mu0Un","executionInfo":{"status":"ok","timestamp":1665916021894,"user_tz":-540,"elapsed":22248,"user":{"displayName":"엄태균","userId":"09048701429252824620"}},"outputId":"72014e4f-111b-41d9-d381-be544e7372e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers==4.8.2\n","!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install torch \n","\n","!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xo3_-TiXvCWi","executionInfo":{"status":"ok","timestamp":1665916196752,"user_tz":-540,"elapsed":174861,"user":{"displayName":"엄태균","userId":"09048701429252824620"}},"outputId":"64fe2def-4f90-4fcd-80c6-0f265092514f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.8.2\n","  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 29.1 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (5.0.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (4.64.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (3.8.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (1.21.6)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 51.6 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 49.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (2022.6.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers==4.8.2) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.8.2) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.8.2) (3.9.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.2) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.2) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.2) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.2) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.2) (1.2.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=fcdd676c511f91973f24aa3af8051ca75a63b542971b5e096c75e93afaf153af\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.8.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mxnet\n","  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[K     |████████████████████████████████| 49.1 MB 1.9 MB/s \n","\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.9.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[K     |████████████████████████████████| 344 kB 30.2 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.6)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.32)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.4)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.9)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595730 sha256=b411beb24e41c82f1ace364c941771fc969473fe4bd9a4152b1ec93d85ce41b2\n","  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 34.3 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-2clz8fpb\n","  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-2clz8fpb\n","Collecting boto3<=1.15.18\n","  Downloading boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n","\u001b[K     |████████████████████████████████| 129 kB 34.4 MB/s \n","\u001b[?25hRequirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.10.0)\n","Collecting mxnet<=1.7.0.post2,>=1.4.0\n","  Downloading mxnet-1.7.0.post2-py2.py3-none-manylinux2014_x86_64.whl (54.7 MB)\n","\u001b[K     |████████████████████████████████| 54.7 MB 17 kB/s \n","\u001b[?25hCollecting onnxruntime<=1.8.0,==1.8.0\n","  Downloading onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[K     |████████████████████████████████| 4.5 MB 49.8 MB/s \n","\u001b[?25hCollecting sentencepiece<=0.1.96,>=0.1.6\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 44.3 MB/s \n","\u001b[?25hCollecting torch<=1.10.1,>=1.7.0\n","  Downloading torch-1.10.1-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n","\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.2 MB/s eta 0:00:42tcmalloc: large alloc 1147494400 bytes == 0x3a130000 @  0x7f7f3888a615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n","\u001b[K     |████████████████████████████████| 881.9 MB 16 kB/s \n","\u001b[?25hCollecting transformers<=4.8.1,>=4.8.1\n","  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 40.8 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.17.3)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.12)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.21.6)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting s3transfer<0.4.0,>=0.3.0\n","  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n","\u001b[K     |████████████████████████████████| 73 kB 2.2 MB/s \n","\u001b[?25hCollecting botocore<1.19.0,>=1.18.18\n","  Downloading botocore-1.18.18-py2.py3-none-any.whl (6.7 MB)\n","\u001b[K     |████████████████████████████████| 6.7 MB 43.1 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n","Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.7/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.24.3)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.32)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (21.3)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (0.8.4)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.23.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.9.24)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.1.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (5.0.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.8.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.53)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.10.3)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.12)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.9.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (7.1.2)\n","Building wheels for collected packages: kobert\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15708 sha256=ec0c83bf927107cd2d2c5330cb89a859f90cc30e104f1781851d917e07653502\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ze0o2f0d/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n","Successfully built kobert\n","Installing collected packages: jmespath, botocore, s3transfer, transformers, torch, sentencepiece, onnxruntime, mxnet, boto3, kobert\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.8.2\n","    Uninstalling transformers-4.8.2:\n","      Successfully uninstalled transformers-4.8.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: sentencepiece\n","    Found existing installation: sentencepiece 0.1.97\n","    Uninstalling sentencepiece-0.1.97:\n","      Successfully uninstalled sentencepiece-0.1.97\n","  Attempting uninstall: mxnet\n","    Found existing installation: mxnet 1.9.1\n","    Uninstalling mxnet-1.9.1:\n","      Successfully uninstalled mxnet-1.9.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.15.18 botocore-1.18.18 jmespath-0.10.0 kobert-0.2.3 mxnet-1.7.0.post2 onnxruntime-1.8.0 s3transfer-0.3.7 sentencepiece-0.1.96 torch-1.10.1 transformers-4.8.1\n"]}]},{"cell_type":"code","source":["\n","# torch\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","import pandas as pd\n","\n","#kobert\n","from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","device = torch.device(\"cuda:0\")\n","\n","#BERT 모델, Vocabulary 불러오기 필수\n","bertmodel, vocab = get_pytorch_kobert_model()\n","\n","\n","# KoBERT에 입력될 데이터셋 정리\n","class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n","                pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))  \n","\n","# 모델 정의\n","class BERTClassifier(nn.Module): ## 클래스를 상속\n","    def __init__(self,\n","                bert,\n","                hidden_size = 768,\n","                num_classes=7,   ##클래스 수 조정##\n","                dr_rate=None,\n","                params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)\n","\n","# Setting parameters\n","max_len = 64\n","batch_size = 16\n","warmup_ratio = 0.1\n","num_epochs = 3\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5\n","\n","## 학습 모델 로드\n","PATH = '/content/drive/MyDrive/Colab Notebooks/Model/'\n","model = torch.load(PATH + 'KoBERT_model.pt')  # 전체 모델을 통째로 불러옴, 클래스 선언 필수\n","model.load_state_dict(torch.load(PATH + 'model_state_dict.pt'))  # state_dict를 불러 온 후, 모델에 저장\n","\n","#토큰화\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n","\n","def new_softmax(a) : \n","    c = np.max(a) # 최댓값\n","    exp_a = np.exp(a-c) # 각각의 원소에 최댓값을 뺀 값에 exp를 취한다. (이를 통해 overflow 방지)\n","    sum_exp_a = np.sum(exp_a)\n","    y = (exp_a / sum_exp_a) * 100\n","    return np.round(y, 3)\n","\n","\n","# 예측 모델 설정\n","def predict(predict_sentence):\n","\n","    data = [predict_sentence, '0']\n","    dataset_another = [data]\n","\n","    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n","    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n","    \n","    model.eval()\n","\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","\n","        out = model(token_ids, valid_length, segment_ids)\n","\n","        # test_eval=[]\n","        # for i in out:\n","        #     logits=i\n","        #     logits = logits.detach().cpu().numpy()\n","        #     min_v = min(logits)\n","        #     total = 0\n","        #     probability = []\n","        #     logits = np.round(new_softmax(logits), 3).tolist()\n","        #     for logit in logits:\n","        #         print(logit)\n","        #         probability.append(np.round(logit, 3))\n","\n","          \n","    return out\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"56FJxZLPvEJI","executionInfo":{"status":"ok","timestamp":1665916241082,"user_tz":-540,"elapsed":44335,"user":{"displayName":"엄태균","userId":"09048701429252824620"}},"outputId":"82b8fc14-4861-4471-c2f4-5680853b742b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/.cache/kobert_v1.zip[██████████████████████████████████████████████████]\n","/content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n","using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"]}]},{"cell_type":"code","source":["import warnings\n","import librosa\n","import librosa.display\n","import soundfile\n","import os, glob, pickle\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import pandas as pd\n","# import seaborn as sns\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","import sklearn\n","warnings.filterwarnings(action='ignore')"],"metadata":{"id":"N--mWQkYZ-Ub","executionInfo":{"status":"ok","timestamp":1665917254602,"user_tz":-540,"elapsed":1668,"user":{"displayName":"엄태균","userId":"09048701429252824620"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["def extract_feature(file_name, mfcc, chroma, mel):\n","    with soundfile.SoundFile(file_name) as sound_file:\n","        X = sound_file.read(dtype=\"float32\")\n","        sample_rate=sound_file.samplerate\n","        if chroma:\n","            stft=np.abs(librosa.stft(X))\n","        result=np.array([])\n","        if mfcc:\n","            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n","            result=np.hstack((result, mfccs))\n","        if chroma:\n","            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n","            result=np.hstack((result, chroma))\n","        if mel:\n","            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n","            result=np.hstack((result, mel))\n","    return result"],"metadata":{"id":"HiYLbeguaA77","executionInfo":{"status":"ok","timestamp":1665917263868,"user_tz":-540,"elapsed":6,"user":{"displayName":"엄태균","userId":"09048701429252824620"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["audioFilePath ='/content/drive/MyDrive/Colab Notebooks/Data/0001_G1A3E1S0C0_PSB_000001.wav'"],"metadata":{"id":"g_LVjXBbaChb","executionInfo":{"status":"ok","timestamp":1665917416234,"user_tz":-540,"elapsed":4,"user":{"displayName":"엄태균","userId":"09048701429252824620"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["voiceParam = extract_feature(audioFilePath,True,True,True)"],"metadata":{"id":"08e05k9CapCk","executionInfo":{"status":"ok","timestamp":1665917429330,"user_tz":-540,"elapsed":1616,"user":{"displayName":"엄태균","userId":"09048701429252824620"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["voiceParam"],"metadata":{"id":"purjqQ8Maq0Q","executionInfo":{"status":"ok","timestamp":1665917434109,"user_tz":-540,"elapsed":4,"user":{"displayName":"엄태균","userId":"09048701429252824620"}},"outputId":"401fbbcc-cd40-4e81-ea46-f409a721ed7c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-4.10504181e+02,  1.23570107e+02,  1.89433804e+01,  2.20322742e+01,\n","        6.74792528e+00,  1.63995590e+01, -1.06413708e+01,  5.17997026e+00,\n","        7.22772312e+00, -7.81177461e-01, -3.20249772e+00, -3.64560890e+00,\n","       -7.89813089e+00, -1.01306295e+01, -4.32525110e+00,  5.55748606e+00,\n","       -2.25704908e+00, -6.85884476e+00,  1.43046594e+00,  8.89175236e-01,\n","       -5.41176701e+00,  1.91487819e-01, -1.18871957e-01, -2.84854722e+00,\n","       -6.03678608e+00, -4.02946091e+00, -5.66906929e+00, -4.23324966e+00,\n","       -2.11053920e+00, -7.94421339e+00, -3.97826052e+00, -3.38989949e+00,\n","       -5.62452841e+00, -4.85505152e+00, -1.93656445e+00, -3.11400080e+00,\n","       -3.67292690e+00, -2.40853167e+00, -4.38236237e+00, -4.76423788e+00,\n","        6.50849760e-01,  6.55304909e-01,  6.31699026e-01,  6.43328309e-01,\n","        6.54490232e-01,  6.42884135e-01,  6.76011741e-01,  6.78369820e-01,\n","        6.72527373e-01,  6.97824180e-01,  7.02137589e-01,  6.48222625e-01,\n","        1.61888693e-02,  5.62841177e-01,  5.37431383e+00,  9.09243202e+00,\n","        1.46423597e+01,  1.65745068e+01,  5.68680382e+00,  3.11478090e+00,\n","        5.50921106e+00,  6.64097500e+00,  8.49412823e+00,  1.23237581e+01,\n","        7.91705656e+00,  6.69309711e+00,  4.81533146e+00,  4.07051468e+00,\n","        5.78794861e+00,  2.16276598e+00,  7.38030970e-01,  7.94591308e-01,\n","        4.93313342e-01,  4.67340052e-01,  4.93034154e-01,  2.75860161e-01,\n","        2.43778646e-01,  2.25615442e-01,  1.92679882e-01,  3.35343152e-01,\n","        5.62251210e-01,  6.82459235e-01,  6.78367496e-01,  5.14082849e-01,\n","        4.96327311e-01,  6.83957219e-01,  4.79533523e-01,  2.22032920e-01,\n","        1.96926638e-01,  1.26870081e-01,  7.72844404e-02,  5.76049462e-02,\n","        2.22346075e-02,  1.14074498e-02,  1.32256243e-02,  5.23155853e-02,\n","        2.84226947e-02,  1.34066837e-02,  1.77078545e-02,  8.77545588e-03,\n","        1.65455192e-02,  2.58536767e-02,  1.61461961e-02,  1.23405121e-02,\n","        1.07943825e-02,  1.81271601e-02,  1.52981644e-02,  1.66695062e-02,\n","        1.90842468e-02,  2.37857439e-02,  1.58142596e-02,  1.06946547e-02,\n","        9.27141402e-03,  8.24548397e-03,  6.29868126e-03,  6.07225206e-03,\n","        1.48026394e-02,  1.76650099e-02,  1.41000347e-02,  1.91062391e-02,\n","        2.02428605e-02,  1.56964175e-02,  7.66746840e-03,  3.16313980e-03,\n","        2.50138110e-03,  2.44325143e-03,  1.55215850e-03,  1.86744821e-03,\n","        9.71369969e-04,  9.39208781e-04,  9.12698859e-04,  1.03361369e-03,\n","        1.39835512e-03,  1.10472774e-03,  1.66001497e-03,  2.07765005e-03,\n","        2.90864822e-03,  3.20749264e-03,  3.38277570e-03,  3.00048944e-03,\n","        2.57659703e-03,  6.19914150e-04,  9.76860058e-04,  2.44561955e-03,\n","        3.35160387e-03,  3.14924098e-03,  3.37102776e-03,  7.54592428e-03,\n","        6.45805011e-03,  4.09920746e-03,  3.68263782e-03,  4.30253614e-03,\n","        4.57598688e-03,  6.06934074e-03,  4.57292330e-03,  3.43633187e-03,\n","        2.11595977e-03,  2.09718756e-03,  2.60426896e-03,  2.11148523e-03,\n","        1.21181551e-03,  7.64164841e-04,  6.48014771e-04,  5.74757229e-04,\n","        3.57506709e-04,  1.85190467e-04,  1.48158913e-04,  1.14973751e-04,\n","        1.37982643e-04,  1.07842789e-04,  1.00351645e-04,  8.56261904e-05,\n","        8.51669029e-05,  5.15458196e-05,  2.66163515e-05,  1.41565915e-05,\n","        8.56365841e-06,  7.43809323e-06,  6.76847867e-06,  4.48123819e-06])"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model"],"metadata":{"id":"OW5vkBZ8vIAI","executionInfo":{"status":"ok","timestamp":1665916246123,"user_tz":-540,"elapsed":5047,"user":{"displayName":"엄태균","userId":"09048701429252824620"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["SERmodel = load_model('/content/drive/MyDrive/Colab Notebooks/Model/voice_emotion_CnnModel1008.h5')\n","totalModel=load_model('/content/drive/MyDrive/Colab Notebooks/Model/concatModel10106.h5')"],"metadata":{"id":"DeZ76CzgvJT3","executionInfo":{"status":"ok","timestamp":1665916254612,"user_tz":-540,"elapsed":8491,"user":{"displayName":"엄태균","userId":"09048701429252824620"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# 데이터 받아오는 알고리즘 추가"],"metadata":{"id":"8UbAnFGpvPXA","executionInfo":{"status":"ok","timestamp":1665916254612,"user_tz":-540,"elapsed":10,"user":{"displayName":"엄태균","userId":"09048701429252824620"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["data = np.load('/content/drive/MyDrive/Colab Notebooks/Data/speechEmotion.npz')\n","X_train_SER=data['X_train']\n","y_train_SER=data['y_train']\n","y_test_SER=data['y_test']\n","X_test_SER=data['X_test']"],"metadata":{"id":"i95Nqh-zvbwL","executionInfo":{"status":"ok","timestamp":1665916445313,"user_tz":-540,"elapsed":6556,"user":{"displayName":"엄태균","userId":"09048701429252824620"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["data1 = np.load('/content/drive/MyDrive/Colab Notebooks/Data/sttEmotionTrainTest.npz')\n","X_train_STT=data1['X_train']\n"],"metadata":{"id":"rJSXue09vdBC","executionInfo":{"status":"ok","timestamp":1665916437558,"user_tz":-540,"elapsed":1200,"user":{"displayName":"엄태균","userId":"09048701429252824620"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["#--------------------------------"],"metadata":{"id":"ovDiaMfSvWAY","executionInfo":{"status":"ok","timestamp":1665916272736,"user_tz":-540,"elapsed":3,"user":{"displayName":"엄태균","userId":"09048701429252824620"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def softmax(a) :\n","  exp_a = np.exp(a)\n","  sum_exp_a = np.sum(exp_a)\n","  y=exp_a/sum_exp_a\n","  return y"],"metadata":{"id":"XLUrXCECwO1M","executionInfo":{"status":"ok","timestamp":1665916282658,"user_tz":-540,"elapsed":3,"user":{"displayName":"엄태균","userId":"09048701429252824620"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def emotionReco(serData,terData):\n","  serData =serData.reshape(1,30, 6, 1)\n","  serResult =SERmodel.predict(serData)\n","  terResult =predict(str(terData))\n","  terResult=terResult.cpu().detach().numpy() \n","  terResult=softmax(terResult)\n","  totalData = np.concatenate((serResult[0],terResult[0]))\n","  totalData =totalData.reshape(1,14)\n","  result = totalModel.predict(totalData)\n","  resultIndex =np.argmax(result[0])\n","  if resultIndex == 0:\n","    emotion = '기쁨'\n","  elif resultIndex==1:\n","    emotion = '슬픔'\n","  elif resultIndex==2:\n","    emotion = '분노'\n","  elif resultIndex==3:\n","    emotion = '불안'\n","  elif resultIndex==4:\n","    emotion = '상처'\n","  elif resultIndex==5:\n","    emotion = '당황'\n","  else :\n","    emotion = '중립'\n","  return emotion"],"metadata":{"id":"h0y7SHZvVfFP","executionInfo":{"status":"ok","timestamp":1665916618918,"user_tz":-540,"elapsed":2,"user":{"displayName":"엄태균","userId":"09048701429252824620"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["emotionReco(X_train_SER[430000],X_train_STT[430000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"fAbGOS8cWgFV","executionInfo":{"status":"ok","timestamp":1665916653644,"user_tz":-540,"elapsed":1448,"user":{"displayName":"엄태균","userId":"09048701429252824620"}},"outputId":"0b6759ff-c7d9-4786-ef9f-40a186731c6e"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 18ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["'중립'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["# 감정 스프링으로 보내는 알고리즘 추가할것\n","# emotionReco 사용하면 감정 추출\n"],"metadata":{"id":"6xNCb1KF1i5u","executionInfo":{"status":"ok","timestamp":1665916677037,"user_tz":-540,"elapsed":5,"user":{"displayName":"엄태균","userId":"09048701429252824620"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["from urllib import parse\n","from unicodedata import category\n","from flask import Flask,request,redirect,render_template\n","from sympy import re\n","\n","app = Flask(__name__) # flask 서버객체 생성\n"," \n","# route(경로): 외부에서 접근할 때 페이지 구분을 위한 경로지정\n","@app.route('/')\n","def voice():\n","   \n","    # -- 텍스트 파일 \n","    # --- 음성파일 저장\n","    \n","    emotion = emotionReco(voiceParam, textParam)\n","    \n","    ## 코랩으로 자료 넘기기\n","        url =f\"http://{ip}:8082/ikujo/RecommendFood.jsp?category={category}&{nutrients}{menu}{nutrientsReCo}\"\n"," \n","    return redirect(url)\n","\n","# main함수의 시작을 의미 \n","# 비유하자면 자바의 main(String[] args)메소드와 같은 역할\n","if __name__ == '__main__':\n","    # 웹서버주소(host)와 포트번호(port)를 지정하여 웹 서버 실행\n","    app.run(host='59.0.147.198', port='5000') "],"metadata":{"id":"Mq-LYogc2qfg","executionInfo":{"status":"ok","timestamp":1665916283638,"user_tz":-540,"elapsed":9,"user":{"displayName":"엄태균","userId":"09048701429252824620"}}},"execution_count":26,"outputs":[]}]}